---
title: ã€ŒPythonã€è¯»å–ç«™ç‚¹åœ°å›¾ è‡ªåŠ¨ä¸ºGitalkåˆ›å»ºIssues
date: 2019-02-09
category: etc
tags: ["python"]

---

## å‰è¨€

å‰äº›å¤©ç»™åšå®¢åŠ äº†è¯„è®ºåŠŸèƒ½ï¼Œè¯•äº†Disqusã€Valineç­‰ä¸€å¹²è¯„è®ºç³»ç»Ÿï¼Œæœ€åè¿˜æ˜¯é€‰æ‹©äº†åœ¨å¤§é™†ç›¸å¯¹å‹å¥½è€Œä¸”ç¬¦åˆæŠ€æœ¯åšå®¢é£æ ¼çš„Gitalkã€‚ä½†æ˜¯ç”±äºGitalkæ˜¯åˆ©ç”¨Githubé‡ŒRepoçš„Issueå®ç°è¯„è®ºåŠŸèƒ½ï¼Œæ‰€ä»¥æ¯ç¯‡åšæ–‡éƒ½éœ€è¦æ‰‹åŠ¨åˆ›å»ºIssueï¼Œå¾ˆæ˜¯éº»çƒ¦ã€‚äºæ˜¯å°±æ‰“ç®—ç”¨Pythonå†™ä¸€ä¸ªè‡ªåŠ¨åˆå§‹åŒ–çš„è„šæœ¬ã€‚

## Gitalkçš„åŸç†

çŸ¥å·±çŸ¥å½¼ï¼Œç™¾æˆ˜ä¸æ®†ã€‚å†™è„šæœ¬ä¹‹å‰ï¼Œæˆ‘ä»¬å¾—å…ˆçŸ¥é“Gitalkæ˜¯é€šè¿‡ä»€ä¹ˆç¡®å®šæ–‡ç« å’ŒIssueä¹‹é—´çš„å…³ç³»çš„ã€‚é€šè¿‡æŸ¥çœ‹[æ–‡æ¡£](https://github.com/gitalk/gitalk/blob/master/readme-cn.md)å¯ä»¥å¾—åˆ°ä¸‹é¢ğŸ‘‡å››ä¸ªæˆ‘ä»¬éœ€è¦çš„å‚æ•°ã€‚

<div class="table-container">

<table>

<thead>

<tr>

<th>å‚æ•°</th>

<th>ç±»å‹</th>

<th>è¯´æ˜</th>

<th>é»˜è®¤å€¼</th>

</tr>

</thead>

<tbody>

<tr>

<td>`id`</td>

<td>String</td>

<td>é¡µé¢çš„å”¯ä¸€æ ‡ç¤ºï¼Œé•¿åº¦å°äº50</td>

<td>`location.href`</td>

</tr>

<tr>

<td>`labels`</td>

<td>Array</td>

<td>Issueçš„æ ‡ç­¾</td>

<td>`['Gitalkâ€™]`</td>

</tr>

<tr>

<td>`title`</td>

<td>String</td>

<td>Issueçš„æ ‡é¢˜</td>

<td>`document.title`</td>

</tr>

<tr>

<td>`body`</td>

<td>String</td>

<td>Issueçš„å†…å®¹</td>

<td>`location.href + header.meta[description]`</td>

</tr>

</tbody>

</table>

</div>

é‚£ä¹ˆå†çœ‹çœ‹Gitalkåˆå§‹åŒ–æ—¶è‡ªåŠ¨ç”Ÿæˆçš„Issueï¼š  
![](https://pic.rhinoc.top/15497140095951.jpg)

åœ¨è¢«è¿™å¼ å›¾ä¸­ï¼Œå››ä¸ªå‚æ•°çš„å€¼åˆ†åˆ«ä¸ºï¼š  

```
title: "æ¸²æŸ“æµ‹è¯• | Dicerorhinus"  
labels: ['Gitalk','/post/themes-test.html']  
body: "https://rhinoc.top/post/themes-test.html"  
```

è¯¶ï¼Œ`id`å»å“ªäº†ï¼Ÿ  
å…¶å®ï¼Œ`labels`ä¸­çš„ç¬¬äºŒä¸ªå…ƒç´ `post/themes-test.html`å°±æ˜¯`id`äº†ã€‚

ç°åœ¨æˆ‘ä»¬å¯¹è¿™å››ä¸ªå‚æ•°æœ‰äº†æ›´å¥½åœ°ç†è§£ï¼Œå¯ä»¥å¼€å§‹å†™ç¨‹åºäº†ã€‚

## æµç¨‹å›¾

```
  +-----------------------------+
  |                             |
  |       get urls from         |
  |        sitemap.xml          |
  |                             |
  +--------------+--------------+
                 |
                 |
                 |
  +--------------v--------------+
  |                             |
  |     login into Github       |
  |     get the repository      |
  |                             |
  +--------------+--------------+
                 |
                 |
                 |
+----------------v-----------------+
|                                  |
|   for every url in urls          |
|   create issue                   |
|   if its issue haven't created   |
|                                  |
+----------------------------------+
```

## å‡ ä¸ªè¦ç‚¹

### `id`é¡»åœ¨50ä¸ªå­—ç¬¦ä»¥å†…

æ–‡æ¡£ä¸­å·²ç»æŒ‡æ˜äº†`id`å’Œåšæ–‡ä¸€å¯¹ä¸€çš„å…³ç³»ï¼Œå¹¶ä¸”åœ¨Gitalkè‡ªåŠ¨ç”Ÿæˆçš„Issueä¸­ï¼Œ`id`è¢«è®¾ç½®ä¸ºæ˜¯åšæ–‡æ‰€åœ¨çš„ç›¸å¯¹è·¯å¾„ã€‚ç”±äº`id`è¢«é™åˆ¶åœ¨50ä¸ªå­—ç¬¦ä»¥å†…ï¼Œæ‰€ä»¥å½“ç›¸å¯¹è·¯å¾„æ¯”è¾ƒé•¿æ—¶ï¼Œå°±ä¸é€‚åˆä½œä¸º`id`äº†ï¼Œè¿™æ—¶å€™å¯ä»¥ä½¿ç”¨MD5å°†ç›¸å¯¹è·¯å¾„ç¼–ç ï¼š

```python
def md5(s):
    hash = hashlib.md5()
    hash.update(s.encode('utf8'))
    return hash.hexdigest()
```

ç”±äºæˆ‘çš„åšå®¢ä¸­åšæ–‡çš„ç›¸å¯¹è·¯å¾„åœ¨50ä¸ªå­—ç¬¦ä»¥å†…ï¼Œæ‰€ä»¥å¹¶æœªé‡‡ç”¨MD5ç¼–ç ã€‚

### é˜²æ­¢é‡å¤åˆ›å»ºIssue

ç”±äºç¨‹åºæ¯æ¬¡è¿è¡Œéƒ½è¦éå†ä¸€é`sitemap.xml`ï¼Œè€Œä¸€éæ¥è¯´æˆ‘ä»¬çš„åšå®¢ä¸­åªæœ‰æ–°å†™çš„åšæ–‡æ²¡æœ‰åˆ›å»ºIssueï¼Œå¦‚æœä¸å¯¹ã€Œå·²åˆå§‹åŒ–ã€å’Œã€Œæœªåˆå§‹åŒ–ã€çš„é“¾æ¥åŠ ä»¥åŒºåˆ†ï¼Œå°±ä¼šé‡å¤åˆ›å»ºIssueã€‚

æ‰€ä»¥ï¼Œæˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªæ•°æ®åº“æ¥å‚¨å­˜å“ªäº›é“¾æ¥æ˜¯å·²åˆå§‹åŒ–è¿‡çš„ï¼Œéå†`sitemap.xml`æ—¶ï¼Œå°†å…¶ä¸­çš„ç½‘å€å’Œæ•°æ®åº“å†…å®¹å¯¹æ¯”ï¼Œå¯¹ä¸åœ¨æ•°æ®åº“ä¸­çš„ç½‘å€è¿›è¡Œåˆå§‹åŒ–å¹¶å†™å…¥æ•°æ®åº“ã€‚

## ä»£ç 

```python
import bs4, requests
from github import Github
from urllib.parse import unquote

blogUrl = 'https://***.***.***'
sitemapUrl = 'https://***.***.***/sitemap.xml'
user = 'username'
token = ''
repoFullName = "user/repo"

session = requests.Session()
res = session.get(sitemapUrl)

readExistUrl = open('urls.txt','r')
writeExistUrl = open('urls.txt','a')
existList = readExistUrl.readlines()

# get urls from sitemap
def getSite(smUrl):
    html = requests.get(smUrl)
    soup = bs4.BeautifulSoup(html.text,"lxml")
    urls = soup.select('loc')
    urlset = []
    for url in urls:
        url = str(url)[5:-6]
        url = url.replace('http','https')
        urlset.append(url)
    return urlset

urls = getSite(sitemapUrl)
gh = Github(login_or_token = token)
repo = gh.get_repo(repoFullName)

for url in urls:
    if ((url + '\n') in existList) or (url in existList):
        continue
    title = url.rsplit('/',2)
    title = unquote(title[2])
    labels = ['Gitalk', url[18:]]
    repo.create_issue(title = title ,body = url,labels = labels)
    writeExistUrl.write('\n'+url)
    print(url + ' created')
    
readExistUrl.close()
writeExistUrl.close()
```
