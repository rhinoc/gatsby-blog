---
title: Pythonç¼–ç¨‹å¿«é€Ÿä¸Šæ‰‹ï¼ˆå…­ï¼‰äººäººå½±è§†èµ„æºæœç´¢å™¨
date: 2019-02-02
category: etc
tags: ["python"]

---

## ç¨‹åºæè¿°

è¾“å…¥å…³é”®å­—ï¼Œåœ¨[äººäººå½±è§†](www.zimuzu.io)ä¸­æœç´¢å½±è§†å‰§ï¼Œå›æ˜¾æœç´¢ç»“æœï¼Œè¾“å…¥ç¼–å·å¾—åˆ°ed2ké“¾æ¥ğŸ”—ã€‚  
![](https://pic.rhinoc.top/15490405569586.jpg?imageslim)  
ç”±äºäººäººå½±è§†é‡‡ç”¨ç­‰çº§åˆ¶åº¦ï¼Œèµ„æºä¸‹è½½é“¾æ¥éœ€è¦ç™»å½•åæ‰èƒ½æŸ¥çœ‹ï¼Œæ‰€ä»¥è¿™é‡Œç”¨`session`æ¨¡æ‹Ÿç™»é™†ã€‚è¿™ä¸€å—å‚è€ƒäº†Githubä¸Š[tengbozhang/renren](https://github.com/tengbozhang/renren)è¿™ä¸€é¡¹ç›®ã€‚

## æ¶‰åŠçŸ¥è¯†ç‚¹

*   session
*   requests
*   bs4
*   RegEx

## ä»£ç 

```python
#! python3
# -*- coding: utf-8 -*-

import webbrowser, requests, sys, bs4, re

headers = {
        'Accept':'application/json, text/javascript, */*; q=0.01',
        'Origin':'https://www.zimuzu.tv',
        'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',
        'Content-Type': 'application/x-www-form-urlencoded',
        }

if len(sys.argv) < 2:
    keywords = input()
    url = 'https://www.zimuzu.io/search?keyword='+ keywords +'&type=resource'
else:
    url = 'https://www.zimuzu.io/search?keyword='+' '.join(sys.argv[1:])+'&type=resource'

res = requests.get((url),headers = headers)
res.raise_for_status()
soup = bs4.BeautifulSoup(res.text,"html.parser")

#print search result and make a choice
linkElems = soup.select('.t a')
for piece in linkElems:
    snum = str(piece.get('href'))[10:]
    print('['+ snum +']', end='')
    rr = re.compile(r'"list_title">(.*?)<\/strong>')
    print(rr.findall(str(piece))[0])
cho = input()

#print download urls
dlUrl = 'https://www.zimuzu.io/resource/list/' + cho
username = ''
password = ''
loginurl = 'https://www.zimuzu.io/User/Login/ajaxLogin'
data = "account=" + username + "&password="+ password + "&remember=1"
session = requests.Session()
login = session.post(loginurl,data = data,headers = headers)
dlSoup = bs4.BeautifulSoup(session.get(dlUrl).content.decode('utf-8'),"html.parser")
dlElems = dlSoup.find_all('a', {"type" : "ed2k"})
for piece in dlElems:
    print(piece.get('href'))
```
